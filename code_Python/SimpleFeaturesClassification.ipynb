{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize\n",
    "from skimage.feature import hog\n",
    "from skimage.feature import local_binary_pattern\n",
    "import os\n",
    "from FeatureExtractor import *\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Videos = ['Pigs_49651_960_540_500f','Koi_5652_952_540',\\\n",
    "          'Pigeons_8234_1280_720','Pigeons_4927_960_540_600f', \\\n",
    "          'Pigeons_29033_960_540_300f']\n",
    "\n",
    "# The individual clips should be stored in folders with the respective\n",
    "# names. For example, folder 'Koi_5652_952_540_clips' should contain\n",
    "# subfolders 'Catherine', 'Dwayne', 'Florence', etc, with the \n",
    "# individual images. MATLAB code for splitting the video, storing the\n",
    "# frames and creating the folders with the clips is provided in this\n",
    "# repository.\n",
    "\n",
    "cl_names = ['Linear Discriminant Analysis', '3-nn', 'Decision Tree',\n",
    "            'SVM', 'Bagging', 'Random Forest'] # classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------\n",
    "def select_half_video(folder,bb_file,part = 1):\n",
    "    \n",
    "    bb = pd.read_csv(bb_file,header = None)    \n",
    "    bb = bb.to_numpy()\n",
    "   \n",
    "    # Find the number of frames in the video\n",
    "    lasf_file_name = bb[-1,5]\n",
    "    f = np.int(lasf_file_name[5:10]) \n",
    "    half_f = np.floor(f/2).astype(int)\n",
    "    \n",
    "    images, labels = [],[]\n",
    "    for i in range(len(bb)):\n",
    "        z = bb[i,5] # take the file name\n",
    "        nn = np.int(z[5:10]) # convert to numeric\n",
    "        flag = ((part == 1) & (nn <= half_f)) | \\\n",
    "            ((part == 2) & (nn > half_f)) \n",
    "        if flag:\n",
    "            label = bb[i,0]# take the string label\n",
    "            label = label.replace(' ','') # trim the blanks\n",
    "            filename = bb[i,5] \n",
    "            fn = label+'/'+ label + '_frame_' + filename[5:10] + '.jpg'\n",
    "            img = plt.imread(folder+'/'+fn)\n",
    "            if img is not None:\n",
    "                images.append(img)\n",
    "                labels.append(label)\n",
    "            else:\n",
    "                print(folder+'/'+fn)     \n",
    "            \n",
    "    return images, labels\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_testing_rows(bb_file,part = 1):\n",
    "    \n",
    "    bb = pd.read_csv(bb_file,header = None)    \n",
    "    bb = bb.to_numpy()\n",
    "   \n",
    "    # Find the number of frames in the video\n",
    "    lasf_file_name = bb[-1,5]\n",
    "    f = np.int(lasf_file_name[5:10]) \n",
    "    half_f = np.floor(f/2).astype(int)\n",
    "    \n",
    "    index = []\n",
    "    for i in range(len(bb)):\n",
    "        z = bb[i,5] # take the file name\n",
    "        nn = np.int(z[5:10]) # convert to numeric\n",
    "        flag = ((part == 1) & (nn <= half_f)) | \\\n",
    "            ((part == 2) & (nn > half_f)) \n",
    "        if flag:\n",
    "            index.append(i)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(images, r = 50, verbose = False):\n",
    "    # Extracts basic features.\n",
    "    # All images are first resized to r-by-r pixels.\n",
    "    # Use verbose = True to see a 4x4 grid of images \n",
    "    \n",
    "    if verbose:\n",
    "        plt.figure(figsize = (10,10))\n",
    "        k = 1 # subplot index\n",
    "        khog = 1\n",
    "        grid_size = 4\n",
    "    \n",
    "    for img in images:\n",
    "        if verbose:\n",
    "            if k <= grid_size**2:\n",
    "                plt.subplot(grid_size,grid_size,k)\n",
    "                plt.imshow(img)\n",
    "                plt.axis('Off')\n",
    "                k +=1   \n",
    "        \n",
    "        resized_img = resize(img, (r, r))\n",
    "        \n",
    "        #creating HOG features ----------------------------------------------------\n",
    "        fd = hog(resized_img, orientations=9, pixels_per_cell=(8, 8), \\\n",
    "                    cells_per_block=(1, 1), multichannel=True)\n",
    "\n",
    "        fd = np.reshape(fd,(1,-1))\n",
    "        if 'DataHOG' in locals():\n",
    "            DataHOG = np.append(DataHOG,fd,axis = 0)\n",
    "        else:\n",
    "            DataHOG = fd\n",
    "\n",
    "        radius = 3\n",
    "        n_points = 8 * radius\n",
    "        method = 'default'\n",
    "        \n",
    "        #creating LBP features ----------------------------------------------------\n",
    "        nbins = 50 # this will be my number of features\n",
    "        \n",
    "        lbp_raw = local_binary_pattern(rgb2gray(img), n_points, radius, method)\n",
    "        lbp,_ = np.histogram(lbp_raw,bins = 50)\n",
    "        lbp = lbp/np.sum(lbp)\n",
    "        lbp = np.reshape(lbp,(1,-1))\n",
    "\n",
    "        if 'DataLBP' in locals():\n",
    "            DataLBP = np.append(DataLBP,lbp,axis = 0)\n",
    "        else:\n",
    "            DataLBP = lbp\n",
    "            \n",
    "        #creating Block RGB features -----------------------------------------------       \n",
    "        rgb = fox_get_colour_features(img, fstr = 'RGB', blocks_r = 3, \n",
    "            blocks_c = 3, bins = 20)\n",
    "        rgb = np.reshape(rgb,(1,-1))\n",
    "        if 'DataRGB' in locals():\n",
    "            DataRGB = np.append(DataRGB,rgb,axis = 0)\n",
    "        else:\n",
    "            DataRGB = rgb\n",
    "            \n",
    "        #creating H10 features ---------------------------------------------------\n",
    "        hsv_img = rgb2hsv(img)\n",
    "        hue_img = hsv_img[:, :, 0]\n",
    "        \n",
    "        h10 = fox_get_colour_features(img, fstr = 'H', blocks_r = 1, \n",
    "            blocks_c = 1, bins = 10)\n",
    "        \n",
    "        h10 = np.reshape(h10,(1,-1))\n",
    "        if 'DataH10' in locals():\n",
    "            DataH10 = np.append(DataH10,h10,axis = 0)\n",
    "        else:\n",
    "            DataH10 = h10\n",
    "        \n",
    "    if verbose:\n",
    "        plt.show()\n",
    "   \n",
    "    return DataHOG, DataLBP, DataRGB, DataH10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "#####  Pigs_49651_960_540_500f  #####\n",
      "\n",
      "\n",
      "Training size =  (2711, 56, 56, 3)  Testing size =  (3212, 56, 56, 3) \n",
      "\n",
      "[[2711. 3212.   22.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]]\n",
      "Training\n",
      " [[0.97196606 0.6370343  0.94835854 0.50202877]\n",
      " [0.97786795 0.85171523 0.98081889 0.73921062]\n",
      " [1.         1.         1.         0.9988934 ]\n",
      " [0.99668019 0.08926595 0.08926595 0.22168941]\n",
      " [0.99631132 0.99557359 0.99926226 0.98487643]\n",
      " [1.         1.         1.         0.9988934 ]]\n",
      "\n",
      "Testing\n",
      " [[0.22882939 0.17372354 0.36830635 0.21699875]\n",
      " [0.22540473 0.1369863  0.27303861 0.19178082]\n",
      " [0.10990037 0.10305106 0.1858655  0.18337484]\n",
      " [0.23599004 0.04763387 0.04763387 0.14632628]\n",
      " [0.15535492 0.13013699 0.2135741  0.19769614]\n",
      " [0.2107721  0.16002491 0.28891656 0.20765878]]\n",
      "\n",
      "\n",
      "#####  Koi_5652_952_540  #####\n",
      "\n",
      "\n",
      "Training size =  (916, 56, 56, 3)  Testing size =  (719, 56, 56, 3) \n",
      "\n",
      "[[2711. 3212.   22.]\n",
      " [ 916.  719.    9.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]]\n",
      "Training\n",
      " [[1.         0.72052402 0.98253275 0.79585153]\n",
      " [0.99454148 0.83406114 0.99563319 0.94213974]\n",
      " [1.         1.         1.         1.        ]\n",
      " [1.         0.20960699 0.20960699 0.3220524 ]\n",
      " [0.99563319 0.99017467 1.         0.98689956]\n",
      " [1.         1.         1.         1.        ]]\n",
      "\n",
      "Testing\n",
      " [[0.13212796 0.19888734 0.39082058 0.37413074]\n",
      " [0.06815021 0.16689847 0.20166898 0.46870654]\n",
      " [0.07510431 0.14742698 0.20862309 0.5744089 ]\n",
      " [0.09179416 0.05563282 0.05563282 0.08205841]\n",
      " [0.09040334 0.16133519 0.23087622 0.51460362]\n",
      " [0.0945758  0.15438108 0.2906815  0.54102921]]\n",
      "\n",
      "\n",
      "#####  Pigeons_8234_1280_720  #####\n",
      "\n",
      "\n",
      "Training size =  (2268, 56, 56, 3)  Testing size =  (2291, 56, 56, 3) \n",
      "\n",
      "[[2711. 3212.   22.]\n",
      " [ 916.  719.    9.]\n",
      " [2268. 2291.   13.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]]\n",
      "Training\n",
      " [[0.93694885 0.52557319 0.84876543 0.50088183]\n",
      " [0.92901235 0.74029982 0.93474427 0.83553792]\n",
      " [1.         1.         1.         1.        ]\n",
      " [0.99691358 0.16887125 0.18694885 0.33818342]\n",
      " [0.99779541 0.99206349 0.99823633 0.99426808]\n",
      " [1.         1.         1.         0.99955908]]\n",
      "\n",
      "Testing\n",
      " [[0.18463553 0.20034919 0.38498472 0.33260585]\n",
      " [0.25403754 0.14709734 0.33391532 0.30772588]\n",
      " [0.13836753 0.12265386 0.22261021 0.21344391]\n",
      " [0.18376255 0.18070711 0.09428197 0.33697076]\n",
      " [0.18027062 0.16630292 0.38760367 0.20689655]\n",
      " [0.2138804  0.18987342 0.37363597 0.24749018]]\n",
      "\n",
      "\n",
      "#####  Pigeons_4927_960_540_600f  #####\n",
      "\n",
      "\n",
      "Training size =  (1574, 56, 56, 3)  Testing size =  (1303, 56, 56, 3) \n",
      "\n",
      "[[2711. 3212.   22.]\n",
      " [ 916.  719.    9.]\n",
      " [2268. 2291.   13.]\n",
      " [1574. 1303.   14.]\n",
      " [   0.    0.    0.]]\n",
      "Training\n",
      " [[0.97585769 0.46442186 0.81321474 0.45425667]\n",
      " [0.94155019 0.70965693 0.94726811 0.70584498]\n",
      " [1.         1.         1.         1.        ]\n",
      " [0.99936468 0.11944091 0.11944091 0.29796696]\n",
      " [0.9974587  0.99110546 0.99364676 0.98856417]\n",
      " [1.         1.         1.         1.        ]]\n",
      "\n",
      "Testing\n",
      " [[0.12432847 0.11895625 0.14888718 0.06830391]\n",
      " [0.07674597 0.11204912 0.06139678 0.06983883]\n",
      " [0.08902533 0.1105142  0.12202609 0.08825787]\n",
      " [0.14428243 0.03453569 0.03453569 0.08442057]\n",
      " [0.09286262 0.10974674 0.10821182 0.08825787]\n",
      " [0.12509593 0.12816577 0.10590944 0.09056025]]\n",
      "\n",
      "\n",
      "#####  Pigeons_29033_960_540_300f  #####\n",
      "\n",
      "\n",
      "Training size =  (2148, 56, 56, 3)  Testing size =  (2241, 56, 56, 3) \n",
      "\n",
      "[[2711. 3212.   22.]\n",
      " [ 916.  719.    9.]\n",
      " [2268. 2291.   13.]\n",
      " [1574. 1303.   14.]\n",
      " [2148. 2241.   20.]]\n",
      "Training\n",
      " [[0.99301676 0.72905028 0.97579143 0.59124767]\n",
      " [0.98603352 0.83612663 0.98882682 0.78165736]\n",
      " [1.         1.         1.         0.99860335]\n",
      " [0.9972067  0.1443203  0.18063315 0.24068901]\n",
      " [0.99860335 0.99348231 0.9990689  0.98696462]\n",
      " [1.         1.         1.         0.99860335]]\n",
      "\n",
      "Testing\n",
      " [[0.38732709 0.33199465 0.53145917 0.17358322]\n",
      " [0.35341365 0.243195   0.42570281 0.23293173]\n",
      " [0.16956716 0.22222222 0.22534583 0.19946452]\n",
      " [0.39402053 0.04730031 0.12271307 0.16733601]\n",
      " [0.22846943 0.26104418 0.32574743 0.22846943]\n",
      " [0.29986613 0.30477465 0.44756805 0.24274877]]\n",
      "[[2711. 3212.   22.]\n",
      " [ 916.  719.    9.]\n",
      " [2268. 2291.   13.]\n",
      " [1574. 1303.   14.]\n",
      " [2148. 2241.   20.]]\n"
     ]
    }
   ],
   "source": [
    "##############################################\n",
    "# CALCULATIONS\n",
    "\n",
    "# Calculate and display the training and testing accuracies\n",
    "# of the 6 classifiers and the 4 data representations:\n",
    "# HOG, LBP, RGB, H10. The data representations as well as\n",
    "# the labels for the training and testing data are stored \n",
    "# in csv files. Each file contains the training data\n",
    "# followed by the testing data.\n",
    "\n",
    "Sizes = np.zeros((len(Videos),3)) \n",
    "# info about training and testing data\n",
    "\n",
    "plot_flag = False\n",
    "r = 56\n",
    "\n",
    "for v in range(len(Videos)):\n",
    "    \n",
    "    video = Videos[v]\n",
    "\n",
    "    print('\\n\\n#####  ' + video + '  #####\\n\\n')\n",
    "    \n",
    "    folder = \"../\" + video + \"_clips\"\n",
    "    bb_file = \"../BB_\" + video + \".csv\"\n",
    "\n",
    "    # Read training and testing data (half video; must not be random!)\n",
    "    imds_1,labels_1 = select_half_video(folder,bb_file,part = 1) # training\n",
    "    imds_2,labels_2 = select_half_video(folder,bb_file,part = 2) # testing\n",
    "    \n",
    "    # Repair the data (missing classes in training data)\n",
    "    # Find missing classes and remove those from both sets\n",
    "\n",
    "    ll = list(np.sort(np.unique(labels_1)))\n",
    "    n_classes = len(ll)\n",
    "\n",
    "    X_train_im = []\n",
    "    X_train = []\n",
    "    y_train_num = []\n",
    "    for i in range(len(imds_1)):\n",
    "        y_train_num.append(ll.index(labels_1[i]))\n",
    "        X_train.append(resize(imds_1[i], (r, r)))\n",
    "        X_train_im.append(imds_1[i])   \n",
    "    X_train = np.array(X_train)/255                       \n",
    "\n",
    "    X_test_im = []\n",
    "    X_test = []\n",
    "    y_test_num = [] # numerical testing labels\n",
    "    for i in range(len(imds_2)):\n",
    "        if labels_2[i] in set(ll):\n",
    "            y_test_num.append(ll.index(labels_2[i]))\n",
    "            X_test.append(resize(imds_2[i], (r, r)))\n",
    "            X_test_im.append(imds_2[i])\n",
    "    X_test = np.array(X_test)/255    \n",
    "\n",
    "    print('Training size = ',X_train.shape,' Testing size = ',X_test.shape, '\\n')\n",
    "    \n",
    "    Sizes[v,0] = len(y_train_num)\n",
    "    Sizes[v,1] = len(y_test_num)\n",
    "    Sizes[v,2] = n_classes\n",
    "    \n",
    "    print(Sizes)\n",
    "    \n",
    "    data_train = extract_features(X_train, r = r, verbose = False)\n",
    "    data_test = extract_features(X_test, r = r, verbose = False)\n",
    "    \n",
    "    # Plot some classes to verify that the labels are intact\n",
    "    if plot_flag: \n",
    "        \n",
    "        zzz = np.where(np.array(y_train_num) == 2)\n",
    "        Class_train_2 = []\n",
    "        for k in range(len(zzz[0])):\n",
    "            p = X_train_im[zzz[0][k]]\n",
    "            Class_train_2.append(p)\n",
    "\n",
    "        zzz = np.where(np.array(y_test_num) == 3)\n",
    "        Class_test_3 = []\n",
    "        for k in range(len(zzz[0])):\n",
    "            p = X_test_im[zzz[0][k]]\n",
    "            Class_test_3.append(p)\n",
    "\n",
    "        plt.figure()\n",
    "        print(ll[2])\n",
    "        random_image_montage(Class_train_2)\n",
    "\n",
    "        plt.figure()\n",
    "        print(ll[3])\n",
    "        random_image_montage(Class_test_3)\n",
    "\n",
    "    # Classification --------------------------------\n",
    "        \n",
    "    cla = [] # accumlate the classifiers\n",
    "    cla.append(LinearDiscriminantAnalysis())\n",
    "    cla.append(KNeighborsClassifier())\n",
    "    cla.append(DecisionTreeClassifier())\n",
    "    cla.append(SVC(gamma=0.1, kernel=\"rbf\"))\n",
    "    cla.append(BaggingClassifier())\n",
    "    cla.append(RandomForestClassifier())\n",
    "    \n",
    "    DataNames = ['DataHOG', 'DataLBP', 'DataRGB', 'DataH10']\n",
    "    \n",
    "\n",
    "    accs = np.zeros((len(cl_names),len(DataNames)))\n",
    "    accs_tr = np.zeros((len(cl_names),len(DataNames)))\n",
    "    for i in range(len(cl_names)):\n",
    "        classifier = cla[i]\n",
    "        for j in range(len(DataNames)):\n",
    "            current_training_data = data_train[j]\n",
    "            current_testing_data = data_test[j]\n",
    "            classifier.fit(current_training_data,y_train_num)\n",
    "            assigned_labels = classifier.predict(current_testing_data)\n",
    "            accs[i,j] = np.mean(y_test_num == assigned_labels)\n",
    "            assigned_labels = classifier.predict(current_training_data)\n",
    "            accs_tr[i,j] = np.mean(y_train_num == assigned_labels)\n",
    "\n",
    "    print('Training\\n',accs_tr)\n",
    "    print('\\nTesting\\n',accs)\n",
    "\n",
    "    # Save results\n",
    "    np.savetxt(\"ClassifierAccSimpleFeatures_\"+ \\\n",
    "        video+\".csv\", accs, delimiter=\",\")   \n",
    "    \n",
    "    DataHOG = np.vstack((data_train[0],data_test[0]))\n",
    "    DataLBP = np.vstack((data_train[1],data_test[1]))\n",
    "    DataRGB = np.vstack((data_train[2],data_test[2]))\n",
    "    DataH10 = np.vstack((data_train[3],data_test[3]))\n",
    "    Labels = np.vstack((np.reshape(y_train_num,(-1,1)), \\\n",
    "                        np.reshape(y_test_num,(-1,1))))\n",
    "    \n",
    "    \n",
    "    np.savetxt(video+\"_DataHOG.csv\", DataHOG, delimiter=\",\")\n",
    "    np.savetxt(video+\"_DataLBP.csv\", DataLBP, delimiter=\",\")\n",
    "    np.savetxt(video+\"_DataRGB.csv\", DataRGB, delimiter=\",\")\n",
    "    np.savetxt(video+\"_DataH10.csv\", DataH10, delimiter=\",\")\n",
    "    np.savetxt(video+\"_Labels.csv\", Labels, delimiter=\",\")\n",
    "\n",
    "print(Sizes)\n",
    "np.savetxt('TrainingTestingSizes.csv', Sizes, delimiter=\",\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
