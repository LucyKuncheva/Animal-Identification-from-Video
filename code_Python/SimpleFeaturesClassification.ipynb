{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize\n",
    "from skimage.feature import hog\n",
    "from skimage.feature import local_binary_pattern\n",
    "import os\n",
    "from FeatureExtractor import *\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Videos = ['Pigs_49651_960_540_500f','Koi_5652_952_540',\\\n",
    "          'Pigeons_8234_1280_720','Pigeons_4927_960_540_600f', \\\n",
    "          'Pigeons_29033_960_540_300f']\n",
    "\n",
    "# The individual clips should be stored in folders with the respective\n",
    "# names. For example, folder 'Koi_5652_952_540_clips' should contain\n",
    "# subfolders 'Catherine', 'Dwayne', 'Florence', etc, with the \n",
    "# individual images. MATLAB code for splitting the video, storing the\n",
    "# frames and creating the folders with the clips is provided in this\n",
    "# repository.\n",
    "\n",
    "cl_names = ['Linear Discriminant Analysis', '3-nn', 'Decision Tree',\n",
    "            'SVM', 'Bagging', 'Random Forest'] # classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------\n",
    "def select_half_video(folder,bb_file,part = 1):\n",
    "    \n",
    "    bb = pd.read_csv(bb_file,header = None)    \n",
    "    bb = bb.to_numpy()\n",
    "   \n",
    "    # Find the number of frames in the video\n",
    "    lasf_file_name = bb[-1,5]\n",
    "    f = np.int(lasf_file_name[5:10]) \n",
    "    half_f = np.floor(f/2).astype(int)\n",
    "    \n",
    "    images, labels = [],[]\n",
    "    for i in range(len(bb)):\n",
    "        z = bb[i,5] # take the file name\n",
    "        nn = np.int(z[5:10]) # convert to numeric\n",
    "        flag = ((part == 1) & (nn <= half_f)) | \\\n",
    "            ((part == 2) & (nn > half_f)) \n",
    "        if flag:\n",
    "            label = bb[i,0]# take the string label\n",
    "            label = label.replace(' ','') # trim the blanks\n",
    "            filename = bb[i,5] \n",
    "            fn = label+'/'+ label + '_frame_' + filename[5:10] + '.jpg'\n",
    "            img = plt.imread(folder+'/'+fn)\n",
    "            if img is not None:\n",
    "                images.append(img)\n",
    "                labels.append(label)\n",
    "            else:\n",
    "                print(folder+'/'+fn)     \n",
    "            \n",
    "    return images, labels\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_testing_rows(bb_file,part = 1):\n",
    "    \n",
    "    bb = pd.read_csv(bb_file,header = None)    \n",
    "    bb = bb.to_numpy()\n",
    "   \n",
    "    # Find the number of frames in the video\n",
    "    lasf_file_name = bb[-1,5]\n",
    "    f = np.int(lasf_file_name[5:10]) \n",
    "    half_f = np.floor(f/2).astype(int)\n",
    "    \n",
    "    index = []\n",
    "    for i in range(len(bb)):\n",
    "        z = bb[i,5] # take the file name\n",
    "        nn = np.int(z[5:10]) # convert to numeric\n",
    "        flag = ((part == 1) & (nn <= half_f)) | \\\n",
    "            ((part == 2) & (nn > half_f)) \n",
    "        if flag:\n",
    "            index.append(i)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(images, r = 50, verbose = False):\n",
    "    # Extracts basic features.\n",
    "    # All images are first resized to r-by-r pixels.\n",
    "    # Use verbose = True to see a 4x4 grid of images \n",
    "    \n",
    "    if verbose:\n",
    "        plt.figure(figsize = (10,10))\n",
    "        k = 1 # subplot index\n",
    "        khog = 1\n",
    "        grid_size = 4\n",
    "    \n",
    "    for img in images:\n",
    "        if verbose:\n",
    "            if k <= grid_size**2:\n",
    "                plt.subplot(grid_size,grid_size,k)\n",
    "                plt.imshow(img)\n",
    "                plt.axis('Off')\n",
    "                k +=1   \n",
    "        \n",
    "        resized_img = resize(img, (r, r))\n",
    "        \n",
    "        #creating HOG features ----------------------------------------------------\n",
    "        fd = hog(resized_img, orientations=9, pixels_per_cell=(8, 8), \\\n",
    "                    cells_per_block=(1, 1), multichannel=True)\n",
    "\n",
    "        fd = np.reshape(fd,(1,-1))\n",
    "        if 'DataHOG' in locals():\n",
    "            DataHOG = np.append(DataHOG,fd,axis = 0)\n",
    "        else:\n",
    "            DataHOG = fd\n",
    "\n",
    "        radius = 3\n",
    "        n_points = 8 * radius\n",
    "        method = 'default'\n",
    "        \n",
    "        #creating LBP features ----------------------------------------------------\n",
    "        nbins = 50 # this will be my number of features\n",
    "        \n",
    "        lbp_raw = local_binary_pattern(rgb2gray(img), n_points, radius, method)\n",
    "        lbp,_ = np.histogram(lbp_raw,bins = 50)\n",
    "        lbp = lbp/np.sum(lbp)\n",
    "        lbp = np.reshape(lbp,(1,-1))\n",
    "\n",
    "        if 'DataLBP' in locals():\n",
    "            DataLBP = np.append(DataLBP,lbp,axis = 0)\n",
    "        else:\n",
    "            DataLBP = lbp\n",
    "            \n",
    "        #creating Block RGB features -----------------------------------------------       \n",
    "        rgb = fox_get_colour_features(img, fstr = 'RGB', blocks_r = 3, \n",
    "            blocks_c = 3, bins = 20)\n",
    "        rgb = np.reshape(rgb,(1,-1))\n",
    "        if 'DataRGB' in locals():\n",
    "            DataRGB = np.append(DataRGB,rgb,axis = 0)\n",
    "        else:\n",
    "            DataRGB = rgb\n",
    "            \n",
    "        #creating H10 features ---------------------------------------------------\n",
    "        hsv_img = rgb2hsv(img)\n",
    "        hue_img = hsv_img[:, :, 0]\n",
    "        \n",
    "        h10 = fox_get_colour_features(img, fstr = 'H', blocks_r = 1, \n",
    "            blocks_c = 1, bins = 10)\n",
    "        \n",
    "        h10 = np.reshape(h10,(1,-1))\n",
    "        if 'DataH10' in locals():\n",
    "            DataH10 = np.append(DataH10,h10,axis = 0)\n",
    "        else:\n",
    "            DataH10 = h10\n",
    "        \n",
    "    if verbose:\n",
    "        plt.show()\n",
    "   \n",
    "    return DataHOG, DataLBP, DataRGB, DataH10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##############################################\n",
    "# CALCULATIONS\n",
    "\n",
    "# Calculate and display the training and testing accuracies\n",
    "# of the 6 classifiers and the 4 data representations:\n",
    "# HOG, LBP, RGB, H10. The data representations as well as\n",
    "# the labels for the training and testing data are stored \n",
    "# in csv files. Each file contains the training data\n",
    "# followed by the testing data.\n",
    "\n",
    "Sizes = np.zeros((len(Videos),3)) \n",
    "# info about training and testing data\n",
    "\n",
    "plot_flag = False\n",
    "r = 56\n",
    "\n",
    "for v in range(len(Videos)):\n",
    "    \n",
    "    video = Videos[v]\n",
    "\n",
    "    print('\\n\\n#####  ' + video + '  #####\\n\\n')\n",
    "    \n",
    "    folder = \"../\" + video + \"_clips\"\n",
    "    bb_file = \"../BB_\" + video + \".csv\"\n",
    "\n",
    "    # Read training and testing data (half video; must not be random!)\n",
    "    imds_1,labels_1 = select_half_video(folder,bb_file,part = 1) # training\n",
    "    imds_2,labels_2 = select_half_video(folder,bb_file,part = 2) # testing\n",
    "    \n",
    "    # Repair the data (missing classes in training data)\n",
    "    # Find missing classes and remove those from both sets\n",
    "\n",
    "    ll = list(np.sort(np.unique(labels_1)))\n",
    "    n_classes = len(ll)\n",
    "\n",
    "    X_train_im = []\n",
    "    X_train = []\n",
    "    y_train_num = []\n",
    "    for i in range(len(imds_1)):\n",
    "        y_train_num.append(ll.index(labels_1[i]))\n",
    "        X_train.append(resize(imds_1[i], (r, r)))\n",
    "        X_train_im.append(imds_1[i])   \n",
    "    X_train = np.array(X_train)/255                       \n",
    "\n",
    "    X_test_im = []\n",
    "    X_test = []\n",
    "    y_test_num = [] # numerical testing labels\n",
    "    for i in range(len(imds_2)):\n",
    "        if labels_2[i] in set(ll):\n",
    "            y_test_num.append(ll.index(labels_2[i]))\n",
    "            X_test.append(resize(imds_2[i], (r, r)))\n",
    "            X_test_im.append(imds_2[i])\n",
    "    X_test = np.array(X_test)/255    \n",
    "\n",
    "    print('Training size = ',X_train.shape,' Testing size = ',X_test.shape, '\\n')\n",
    "    \n",
    "    Sizes[v,0] = len(y_train_num)\n",
    "    Sizes[v,1] = len(y_test_num)\n",
    "    Sizes[v,2] = n_classes\n",
    "    \n",
    "    print(Sizes)\n",
    "    \n",
    "    data_train = extract_features(X_train, r = r, verbose = False)\n",
    "    data_test = extract_features(X_test, r = r, verbose = False)\n",
    "    \n",
    "    # Plot some classes to verify that the labels are intact\n",
    "    if plot_flag: \n",
    "        \n",
    "        zzz = np.where(np.array(y_train_num) == 2)\n",
    "        Class_train_2 = []\n",
    "        for k in range(len(zzz[0])):\n",
    "            p = X_train_im[zzz[0][k]]\n",
    "            Class_train_2.append(p)\n",
    "\n",
    "        zzz = np.where(np.array(y_test_num) == 3)\n",
    "        Class_test_3 = []\n",
    "        for k in range(len(zzz[0])):\n",
    "            p = X_test_im[zzz[0][k]]\n",
    "            Class_test_3.append(p)\n",
    "\n",
    "        plt.figure()\n",
    "        print(ll[2])\n",
    "        random_image_montage(Class_train_2)\n",
    "\n",
    "        plt.figure()\n",
    "        print(ll[3])\n",
    "        random_image_montage(Class_test_3)\n",
    "\n",
    "    # Classification --------------------------------\n",
    "        \n",
    "    cla = [] # accumlate the classifiers\n",
    "    cla.append(LinearDiscriminantAnalysis())\n",
    "    cla.append(KNeighborsClassifier())\n",
    "    cla.append(DecisionTreeClassifier())\n",
    "    cla.append(SVC(gamma=0.1, kernel=\"rbf\"))\n",
    "    cla.append(BaggingClassifier())\n",
    "    cla.append(RandomForestClassifier())\n",
    "    \n",
    "    DataNames = ['DataHOG', 'DataLBP', 'DataRGB', 'DataH10']\n",
    "    \n",
    "\n",
    "    accs = np.zeros((len(cl_names),len(DataNames)))\n",
    "    accs_tr = np.zeros((len(cl_names),len(DataNames)))\n",
    "    for i in range(len(cl_names)):\n",
    "        classifier = cla[i]\n",
    "        for j in range(len(DataNames)):\n",
    "            current_training_data = data_train[j]\n",
    "            current_testing_data = data_test[j]\n",
    "            classifier.fit(current_training_data,y_train_num)\n",
    "            assigned_labels = classifier.predict(current_testing_data)\n",
    "            accs[i,j] = np.mean(y_test_num == assigned_labels)\n",
    "            assigned_labels = classifier.predict(current_training_data)\n",
    "            accs_tr[i,j] = np.mean(y_train_num == assigned_labels)\n",
    "\n",
    "    print('Training\\n',accs_tr)\n",
    "    print('\\nTesting\\n',accs)\n",
    "\n",
    "    # Save results\n",
    "    np.savetxt(\"ClassifierAccSimpleFeatures_\"+ \\\n",
    "        video+\".csv\", accs, delimiter=\",\")   \n",
    "    \n",
    "    DataHOG = np.vstack((data_train[0],data_test[0]))\n",
    "    DataLBP = np.vstack((data_train[1],data_test[1]))\n",
    "    DataRGB = np.vstack((data_train[2],data_test[2]))\n",
    "    DataH10 = np.vstack((data_train[3],data_test[3]))\n",
    "    Labels = np.vstack((np.reshape(y_train_num,(-1,1)), \\\n",
    "                        np.reshape(y_test_num,(-1,1))))\n",
    "    \n",
    "    \n",
    "    np.savetxt(video+\"_DataHOG.csv\", DataHOG, delimiter=\",\")\n",
    "    np.savetxt(video+\"_DataLBP.csv\", DataLBP, delimiter=\",\")\n",
    "    np.savetxt(video+\"_DataRGB.csv\", DataRGB, delimiter=\",\")\n",
    "    np.savetxt(video+\"_DataH10.csv\", DataH10, delimiter=\",\")\n",
    "    np.savetxt(video+\"_Labels.csv\", Labels, delimiter=\",\")\n",
    "\n",
    "print(Sizes)\n",
    "np.savetxt('TrainingTestingSizes.csv', Sizes, delimiter=\",\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
